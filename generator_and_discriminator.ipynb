{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lg01wvWnmA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "91a223f1-46e8-4b35-9c8c-fe3c4a65311f"
      },
      "source": [
        "import time \n",
        "b = time.time()\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "import torch.optim as optim\n",
        "import torch.jit as jit \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "a = time.time()\n",
        "print(f'Imports complete in {a-b} seconds.')\n",
        "\n",
        "out_image_shape = (3, 160, 160) # Channels - Height - Width\n",
        "n_latent_vars = 100\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input = nn.Linear(n_latent_vars, 20*20*30)\n",
        "        self.convT1 = nn.ConvTranspose2d(30, 20, kernel_size = (2,2), stride=(2,2), padding=0)\n",
        "        self.convT2 = nn.ConvTranspose2d(20, 10, kernel_size = (2,2), stride=(2,2), padding=0)\n",
        "        self.convT3 = nn.ConvTranspose2d(10, out_image_shape[0], kernel_size = (2,2), stride=(2,2), padding=0)\n",
        "        print('Generator created.')\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.input(x))\n",
        "        #print(x.shape)\n",
        "        x = x.view(1,30,20,20)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.convT1(x))\n",
        "        #print('1=>', x.shape)\n",
        "        x = F.relu(self.convT2(x))\n",
        "        #print('2=>',x.shape)\n",
        "        x = torch.sigmoid(self.convT3(x))\n",
        "        #print('3=>',x.shape)\n",
        "        return x\n",
        "\n",
        "    def init_weights(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.ConvTranspose2d):\n",
        "                nn.init.kaiming_uniform_(module.weight)\n",
        "            elif isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(module.weight)\n",
        "            else:\n",
        "                pass\n",
        "        print('Generator weights initialized as per kaiming uniform criterion.')\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, 3)\n",
        "        self.conv2 = nn.Conv2d(10, 100, 5)\n",
        "        self.conv3 = nn.Conv2d(100, 1, 5)\n",
        "        self.lin1 = nn.Linear(22500, 500)\n",
        "        self.out = nn.Linear(500, 1)\n",
        "        print(f'Discriminator created.')\n",
        "        self.init_weights()\n",
        "\n",
        "    def get_flattened(self, shape_):\n",
        "        prod = 1\n",
        "        for element in shape_:\n",
        "            prod = prod*element\n",
        "        return prod\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(f'1=> {x.shape}')\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(f'2=> {x.shape}')\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(f'3=> {x.shape}')\n",
        "        x = x.view(-1,22500)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = torch.sigmoid(self.out(x))\n",
        "        return x\n",
        "\n",
        "    def init_weights(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                nn.init.kaiming_uniform_(module.weight)\n",
        "            elif isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(module.weight)\n",
        "            else:\n",
        "                pass\n",
        "        print('Discriminator weights initialized as per kaiming uniform criterion.')\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "cpu = torch.device('cpu')\n",
        "print(f'Running on {device}')\n",
        "gen_tracer = torch.rand(100).to(device)\n",
        "dis_tracer = torch.rand(1, *out_image_shape).to(device)\n",
        "gen = Generator().to(device)\n",
        "dis = Discriminator().to(device)\n",
        "traced_gen = jit.trace(gen, gen_tracer).to(device)\n",
        "traced_dis = jit.trace(dis, dis_tracer).to(device)\n",
        "\n",
        "n = 4000\n",
        "b = time.time()\n",
        "for _ in tqdm(range(n)):\n",
        "    gen_out = gen(gen_tracer)\n",
        "    dis_out = dis(gen_out)\n",
        "a = time.time()\n",
        "eagertime = a-b\n",
        "\n",
        "b = time.time()\n",
        "for _ in tqdm(range(n)):\n",
        "    gen_out = traced_gen(gen_tracer)\n",
        "    dis_out = traced_dis(gen_out)\n",
        "a = time.time()\n",
        "statictime = a-b\n",
        "\n",
        "print(f'Static vs Eager execution time = {statictime/eagertime}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imports complete in 0.00013113021850585938 seconds.\n",
            "Running on cuda:0\n",
            "Generator created.\n",
            "Generator weights initialized as per kaiming uniform criterion.\n",
            "Discriminator created.\n",
            "Discriminator weights initialized as per kaiming uniform criterion.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [00:25<00:00, 155.65it/s]\n",
            "100%|██████████| 4000/4000 [00:25<00:00, 154.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Static vs Eager execution time = 1.0061345510181274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}